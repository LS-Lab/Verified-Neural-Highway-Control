{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import highway_env\n",
    "import stable_baselines3\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"highspeed-rew-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/envs/abz/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:437: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  th_object = th.load(file_content, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = stable_baselines3.DQN.load(f\"{name}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQNPolicy(\n",
       "  (q_net): QNetwork(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (q_net): Sequential(\n",
       "      (0): Linear(in_features=25, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (q_net_target): QNetwork(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (q_net): Sequential(\n",
       "      (0): Linear(in_features=25, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxableSB3Policy(torch.nn.Module):\n",
    "    def __init__(self, policy):\n",
    "        super().__init__()\n",
    "        self.policy = policy\n",
    "\n",
    "    def forward(self, observation):\n",
    "        # NOTE: Preprocessing is included, but postprocessing\n",
    "        # (clipping/inscaling actions) is not,\n",
    "        # If needed, you also need to transpose the images so that they are channel first\n",
    "        # use deterministic=False if you want to export the stochastic policy\n",
    "        # policy() returns `actions, values, log_prob` for PPO\n",
    "        return self.policy(observation, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_policy = OnnxableSB3Policy(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_size = model.observation_space.shape\n",
    "dummy_input = torch.randn(1, *observation_size)\n",
    "torch.onnx.export(\n",
    "    onnx_policy,\n",
    "    dummy_input,\n",
    "    f\"{name}.onnx\",\n",
    "    opset_version=12,\n",
    "    input_names=[\"input\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(f\"{name}.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[input: \"/policy/q_net/features_extractor/flatten/Flatten_output_0\"\n",
       "input: \"policy.q_net.q_net.0.weight\"\n",
       "input: \"policy.q_net.q_net.0.bias\"\n",
       "output: \"/policy/q_net/q_net/q_net.0/Gemm_output_0\"\n",
       "name: \"/policy/q_net/q_net/q_net.0/Gemm\"\n",
       "op_type: \"Gemm\"\n",
       "attribute {\n",
       "  name: \"alpha\"\n",
       "  f: 1\n",
       "  type: FLOAT\n",
       "}\n",
       "attribute {\n",
       "  name: \"beta\"\n",
       "  f: 1\n",
       "  type: FLOAT\n",
       "}\n",
       "attribute {\n",
       "  name: \"transB\"\n",
       "  i: 1\n",
       "  type: INT\n",
       "}\n",
       ", input: \"/policy/q_net/q_net/q_net.0/Gemm_output_0\"\n",
       "output: \"/policy/q_net/q_net/q_net.1/Relu_output_0\"\n",
       "name: \"/policy/q_net/q_net/q_net.1/Relu\"\n",
       "op_type: \"Relu\"\n",
       ", input: \"/policy/q_net/q_net/q_net.1/Relu_output_0\"\n",
       "input: \"policy.q_net.q_net.2.weight\"\n",
       "input: \"policy.q_net.q_net.2.bias\"\n",
       "output: \"/policy/q_net/q_net/q_net.2/Gemm_output_0\"\n",
       "name: \"/policy/q_net/q_net/q_net.2/Gemm\"\n",
       "op_type: \"Gemm\"\n",
       "attribute {\n",
       "  name: \"alpha\"\n",
       "  f: 1\n",
       "  type: FLOAT\n",
       "}\n",
       "attribute {\n",
       "  name: \"beta\"\n",
       "  f: 1\n",
       "  type: FLOAT\n",
       "}\n",
       "attribute {\n",
       "  name: \"transB\"\n",
       "  i: 1\n",
       "  type: INT\n",
       "}\n",
       ", input: \"/policy/q_net/q_net/q_net.2/Gemm_output_0\"\n",
       "output: \"/policy/q_net/q_net/q_net.3/Relu_output_0\"\n",
       "name: \"/policy/q_net/q_net/q_net.3/Relu\"\n",
       "op_type: \"Relu\"\n",
       ", input: \"/policy/q_net/q_net/q_net.3/Relu_output_0\"\n",
       "input: \"policy.q_net.q_net.4.weight\"\n",
       "input: \"policy.q_net.q_net.4.bias\"\n",
       "output: \"/policy/q_net/q_net/q_net.4/Gemm_output_0\"\n",
       "name: \"/policy/q_net/q_net/q_net.4/Gemm\"\n",
       "op_type: \"Gemm\"\n",
       "attribute {\n",
       "  name: \"alpha\"\n",
       "  f: 1\n",
       "  type: FLOAT\n",
       "}\n",
       "attribute {\n",
       "  name: \"beta\"\n",
       "  f: 1\n",
       "  type: FLOAT\n",
       "}\n",
       "attribute {\n",
       "  name: \"transB\"\n",
       "  i: 1\n",
       "  type: INT\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.node.pop(0)\n",
    "model.graph.node.pop(0)\n",
    "model.graph.node.pop(-1)\n",
    "model.graph.node.pop(-1)\n",
    "model.graph.node.pop(-1)\n",
    "model.graph.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph.output[0].name = \"/policy/q_net/q_net/q_net.4/Gemm_output_0\"\n",
    "model.graph.output[0].type.tensor_type.shape.dim[0].dim_value=3\n",
    "model.graph.output[0].type.tensor_type.elem_type=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_template = copy.deepcopy(model.graph.output[0].type.tensor_type.shape.dim[0])\n",
    "model.graph.output[0].type.tensor_type.shape.dim.append(dim_template)\n",
    "model.graph.output[0].type.tensor_type.shape.dim[0].dim_value=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dim_value: 1\n",
       ", dim_value: 3\n",
       "]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.output[0].type.tensor_type.shape.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph.node[0].input[0] = \"input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph.input[0].type.tensor_type.shape.dim.pop(-1)\n",
    "#model.graph.input[0].type.tensor_type.shape.dim.pop(-1)\n",
    "model.graph.input[0].type.tensor_type.shape.dim[1].dim_value = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(model, f\"{name}-adjusted.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(f\"{name}-adjusted.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.7166219, 1.4289604, 6.3589163]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "ort_sess = ort.InferenceSession(f\"{name}-adjusted.onnx\")\n",
    "x = np.random.normal(size=(1, 25)).astype(np.float32)\n",
    "ort_sess.run(None, {'input': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
